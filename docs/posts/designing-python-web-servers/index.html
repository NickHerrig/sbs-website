<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Andrew Dailey">
    <meta name="description" content="Simple software that babbles loudly">
    <meta name="keywords" content="blog,developer,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Designing Python Web Servers"/>
<meta name="twitter:description" content="I&rsquo;ve spent the last few days designing and benchmarking extremely minimal pure-Python web servers. There is a tech myth / superstition that exposing python web servers to the internet is a bad idea but I&rsquo;ve seen little to no evidence as to why this is supposedly the case. Are they too slow? Are they too insecure for some reason? One thing is for sure: performance must always be measured, not guessed."/>

    <meta property="og:title" content="Designing Python Web Servers" />
<meta property="og:description" content="I&rsquo;ve spent the last few days designing and benchmarking extremely minimal pure-Python web servers. There is a tech myth / superstition that exposing python web servers to the internet is a bad idea but I&rsquo;ve seen little to no evidence as to why this is supposedly the case. Are they too slow? Are they too insecure for some reason? One thing is for sure: performance must always be measured, not guessed." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://shallowbrooksoftware.com/posts/designing-python-web-servers/" />
<meta property="article:published_time" content="2020-09-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-09-02T00:00:00+00:00" />


    
      <base href="https://shallowbrooksoftware.com/posts/designing-python-web-servers/">
    
    <title>
  Designing Python Web Servers · Shallow Brook Software
</title>

    
      <link rel="canonical" href="https://shallowbrooksoftware.com/posts/designing-python-web-servers/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.11.2/css/all.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.a4f332213a21ce8eb521670c614470c58923aaaf385e2a73982c31dd7642decb.css" integrity="sha256-pPMyITohzo61IWcMYURwxYkjqq84XipzmCwx3XZC3ss=" crossorigin="anonymous" media="screen" />
    

    

    

    

    

    

    <link rel="icon" type="image/png" href="https://shallowbrooksoftware.com/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://shallowbrooksoftware.com/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.68.3" />
  </head>

  
  
  <body class="colorscheme-light">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Shallow Brook Software
    </a>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://shallowbrooksoftware.com/about/">About</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://shallowbrooksoftware.com/projects/">Projects</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://shallowbrooksoftware.com/posts/">Blog</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Designing Python Web Servers</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2020-09-02T00:00:00Z'>
                September 2, 2020
              </time>
            </span>
          </div>
          
          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="/tags/python/">python</a>
      <span class="separator">•</span>
    <a href="/tags/server/">server</a>
      <span class="separator">•</span>
    <a href="/tags/design/">design</a>
      <span class="separator">•</span>
    <a href="/tags/networking/">networking</a></div>

        </div>
      </header>

      <div>
        
        <p>I&rsquo;ve spent the last few days designing and benchmarking extremely minimal pure-Python web servers.
There is a tech myth / superstition that exposing python web servers to the internet is a bad idea but I&rsquo;ve seen little to no evidence as to why this is supposedly the case.
Are they too slow?
Are they too insecure for some reason?
One thing is for sure: performance must always be measured, not guessed.</p>
<h1 id="designs">Designs</h1>
<p>The designs I tested can be grouped into 4 broad categories: sequential, forking, threading, and asynchronous.</p>
<h3 id="sequential">Sequential</h3>
<p>Sequential servers are the simplest and most straightfoward.
They process all clients in the order they arrive, one at a time.
This means that every client has to wait in a potentially very long line before they get service.
I expect this approach to be mediocre.</p>
<h3 id="forking">Forking</h3>
<p>Forking servers spawn a new operating system process for each client that arrives.
This means that clients don&rsquo;t have to wait on each other but more of the server&rsquo;s resources will be consumed.
Additionally, spawning new processes tends to have noticable overhead when many clients connect rapidly.
I expect this approach to be visibly affected by this overhead.</p>
<h3 id="threading">Threading</h3>
<p>Threading servers are similar to forking servers except that they spawn a thread to handle each client instead of a process.
Threads tend to have lower overhead than processes but aren&rsquo;t quite as independent when it comes to grabbing time on the CPU.
They share memory as well as some other server resources.
I expect this approach to perform well since web servers tend be bound by IO, not the CPU.</p>
<h3 id="asynchronous">Asynchronous</h3>
<p>Asynchronous servers double down on the IO-heavy workload of web servers.
They keep all client connections together in such a way that no connections are ever waited on.
Only when data is ready to be read from a client does the server &ldquo;wake up&rdquo; and process it.
I expect this approach to perform very well since it is tailored to fit IO-bound workloads.</p>
<h1 id="benchmark">Benchmark</h1>
<p>The servers were tested whilst running on a minimal <a href="https://www.digitalocean.com/">DigitalOcean</a> Droplet (1 CPU, 1GB RAM).
All of them are using a TCP listen backlog of 128.
Printing each request to stdout is disabled during the benchmark.
For the actual load testing, I used a tool called <a href="https://github.com/rakyll/hey">hey</a>.</p>
<p>It performs 2000 requests spread across 50 concurrent connections:</p>
<pre><code>hey -n 2000 -c 50 http://bloggulus.com
</code></pre><h1 id="results">Results</h1>
<p>I started with a load test against <a href="https://nginx.org/en/">NGINX</a> as a baseline.
I then measured all of the other servers in the same way.</p>
<p>RPS stands for &ldquo;Requests per second&rdquo; and latencies are measured in seconds.
The column &ldquo;% NGINX (RPS)&rdquo; is extra cool in my opinion.
It clearly shows how much room for improvement exists within each design.</p>
<table>
<thead>
<tr>
<th>Server</th>
<th>RPS</th>
<th>Mean Latency</th>
<th>Mode Latency</th>
<th>Worst Latency</th>
<th>% NGINX (RPS)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/nginx/nginx">NGINX</a></td>
<td>672.36</td>
<td>0.07</td>
<td>0.11</td>
<td>0.64</td>
<td>100.00</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/sequential1.py">sequential1.py</a></td>
<td>54.23</td>
<td>0.84</td>
<td>0.92</td>
<td>8.10</td>
<td>8.07</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/sequential2.py">sequential2.py</a></td>
<td>52.77</td>
<td>0.84</td>
<td>0.91</td>
<td>7.85</td>
<td>7.85</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/sequential3.py">sequential3.py</a></td>
<td>45.71</td>
<td>0.78</td>
<td>1.64</td>
<td>15.88</td>
<td>6.80</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/forking1.py">forking1.py</a></td>
<td>8.70</td>
<td>5.60</td>
<td>5.14</td>
<td>10.14</td>
<td>1.29</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/forking2.py">forking2.py</a></td>
<td>81.83</td>
<td>0.54</td>
<td>0.87</td>
<td>7.60</td>
<td>12.17</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/threading1.py">threading1.py</a></td>
<td>78.71</td>
<td>0.52</td>
<td>0.87</td>
<td>7.52</td>
<td>11.71</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/threading2.py">threading2.py</a></td>
<td>79.06</td>
<td>0.51</td>
<td>0.88</td>
<td>7.73</td>
<td>11.76</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/processpool.py">processpool.py</a></td>
<td>48.52</td>
<td>0.71</td>
<td>1.01</td>
<td>8.81</td>
<td>7.22</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/threadpool.py">threadpool.py</a></td>
<td>70.04</td>
<td>0.62</td>
<td>0.87</td>
<td>7.49</td>
<td>10.42</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/nonblocking.py">nonblocking.py</a></td>
<td>79.33</td>
<td>0.53</td>
<td>0.63</td>
<td>5.23</td>
<td>11.80</td>
</tr>
<tr>
<td><a href="https://github.com/theandrew168/bloggulus/blob/master/design/async.py">async.py</a></td>
<td>82.97</td>
<td>0.53</td>
<td>0.84</td>
<td>7.35</td>
<td>12.34</td>
</tr>
</tbody>
</table>
<h1 id="analysis">Analysis</h1>
<p>Pretty interesting stuff!
Some designs were awful, some were middle-of-the-road, and some were decent.
As expected, the simple sequential servers were quite average and all floated around that 50 RPS range.
The <code>forking1.py</code> design was the worst by far.
Spawning a new process per client connection really does add a large amount of overhead.
I&rsquo;m really not sure why it was so much worse than <code>forking2.py</code> which uses Python&rsquo;s builtin <a href="https://docs.python.org/3/library/socketserver.html#socketserver.ForkingTCPServer">ForkingTCPServer</a> (this supposedly does the same thing).
By watching the actually system processes, the latter didn&rsquo;t seem to be creating a new process for each client as it describes.
I wonder if it has some sort of internal &ldquo;max processes&rdquo; limit to prevent things from getting out of hand.</p>
<p>All of the threading servers did well.
I&rsquo;m not surprised by this given that a web server&rsquo;s workload tends to be very IO-bound.
If the workload was more CPU-bound then I&rsquo;d expect to the threading designs rank a bit lower.
The <code>nonblocking.py</code> and <code>async.py</code> servers also performed well for a similar reason: an IO-bound workload.
These two designs both multiplex the socket IO handling around which clients are ready for action <em>right now</em>.
The two &ldquo;pool&rdquo; designs did decent but not as well as their unpooled counterparts.
The overhead of managing the pool must be coming into play here.</p>
<h1 id="existing-servers">Existing Servers</h1>
<p>Just for completeness, I wanted to see how a few existing Python-based web servers stacked up against my quick and dirty designs.
Unsurprisingly, they beat me by a long shot!
Most of them did, at least.</p>
<table>
<thead>
<tr>
<th>Server</th>
<th>RPS</th>
<th>Mean Latency</th>
<th>Mode Latency</th>
<th>Worst Latency</th>
<th>% NGINX (RPS)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/nginx/nginx">NGINX</a></td>
<td>672.36</td>
<td>0.07</td>
<td>0.11</td>
<td>0.64</td>
<td>100.00</td>
</tr>
<tr>
<td><a href="https://docs.gunicorn.org/en/latest/design.html#sync-workers">Gunicorn[sync]</a></td>
<td>46.31</td>
<td>0.99</td>
<td>0.95</td>
<td>8.23</td>
<td>6.89</td>
</tr>
<tr>
<td><a href="https://docs.gunicorn.org/en/latest/design.html#async-workers">Gunicorn[gevent]</a></td>
<td>338.36</td>
<td>0.14</td>
<td>0.09</td>
<td>0.43</td>
<td>50.32</td>
</tr>
<tr>
<td><a href="https://docs.pylonsproject.org/projects/waitress/en/stable/index.html">Waitress</a></td>
<td>449.07</td>
<td>0.10</td>
<td>0.09</td>
<td>0.42</td>
<td>66.79</td>
</tr>
</tbody>
</table>
<p>The synchronous Gunicorn did about as well as my own sequential servers which is to be expected.
Gunicorn with <a href="http://www.gevent.org/">gevent</a> based workers did extremely well.
Gevent is a well-optimized implementation of asynchronous IO with its core event loop written in C (as either <a href="http://software.schmorp.de/pkg/libev.html">libev</a> or <a href="http://libuv.org/">libuv</a>).
I figured that it would be a high performer and I wasn&rsquo;t wrong.</p>
<p>Waitress was the underdog for me but&hellip; Wow!
I was really blown away by its performance.
It even gives NGINX a run for its money by smashing through 67% of its requests per second.
Even more amazing is that Waitress is a pure-Python implementation with zero external dependencies.
Talk about good engineering.</p>
<p>I&rsquo;m definitely going to spend some time reading the source of Waitress to understand more about how they achieve such impressive performance.
Thankfully, they have a well-written <a href="https://docs.pylonsproject.org/projects/waitress/en/stable/design.html">design overview</a> which will be a good place to start.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Moving forward, I plan to use to Waitress as my web server of choice for upcoming Python web projects.
The performance is great (as we&rsquo;ve seen) and it supports a &ldquo;bring your own socket&rdquo; model of initialization.
This is important to me because the apps I deploy to production get their privileged listen sockets (on ports 80 and 443) from <a href="https://www.freedesktop.org/software/systemd/man/systemd.socket.html">systemd</a> as raw file descriptors.</p>
<p>Thanks for reading!</p>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
      <p>simple software that babbles loudly</p>
    
    
      
        © 2020
      
       Andrew Dailey 
    
    
       · 
       <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    

    

  </body>

</html>
